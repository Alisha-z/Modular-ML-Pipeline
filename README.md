# Modular-ML-Pipeline

# Modular Machine Learning Pipeline â€“ Heart Disease Dataset ğŸš¢

This project is a **modular machine learning pipeline** built on the Titanic dataset.  
It follows a clean, structured, and reusable approach to building ML projects.  

The pipeline is divided into the following modules:
- **Data Preprocessing** ğŸ§¹
- **Feature Engineering** ğŸ”§
- **Model Training** ğŸ¤–
- **Model Evaluation** ğŸ“Š

---

## ğŸ“‚ Project Structure

â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Original dataset files (input)
â”‚ â”œâ”€â”€ processed/ # Cleaned and processed datasets (output)
â”‚
â”œâ”€â”€ preprocessing.py # Data loading & preprocessing steps
â”œâ”€â”€ config.py # Feature transformation & encoding
â”œâ”€â”€ train_model.py # Model training script
â”œâ”€â”€ evaluate.py # Model evaluation script
â”œâ”€â”€ utils.py # Helper functions
â”œâ”€â”€ main.py # Orchestrator (runs full pipeline)
â”œâ”€â”€ requirements.txt # Dependencies
â””â”€â”€ README.md # Project documentation

Installed Required Dependies:
pip install -r requirements.txt


Dataset

Place your dataset inside the data/raw/ directory.

For the Titanic dataset, download from Kaggle Titanic Dataset
.

Example file:
data/raw/train.csv
data/raw/test.csv

â–¶ï¸ Usage

You can run the full pipeline with:
python main.py 

This will automatically:

Load and preprocess the raw dataset

Apply feature engineering

Train the ML model (e.g., Logistic Regression, Random Forest, etc.)

Evaluate the model and print metrics

ğŸ§© Run Modules Individually

You can also run specific pipeline stages for debugging:
python preprocessing.py       # Preprocess dataset
python utils.py # Feature transformations
python train_model.py               # Train the model
python evaluate.py            # Evaluate trained model









